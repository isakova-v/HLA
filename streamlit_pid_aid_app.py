import re
from typing import List, Dict
import numpy as np
import pandas as pd
import streamlit as st
import io
from scipy.stats import chi2_contingency, fisher_exact, mannwhitneyu
from statsmodels.stats.multitest import multipletests
import seaborn as sns
import matplotlib.pyplot as plt

# ----------------------
# Config & helpers
# ----------------------

st.set_page_config(page_title="PID/AID Dashboard", layout="wide")

TEXT_COLS_CANDIDATES = [
    "clinical_discuss", "clinical_comments", "comments_interesting_vars",
    "INTERPRET_VAR_table_user", "INTERPRET_VAR_table",
    "IUIS_classification", "combi_diganosis_mcch52", "clin_manifestations",
    "autoiimunity", "markers"
]

ID_COLS = {
    "uin2_fulltxt": ["uin2_fulltxt", "uin2"],
    "uin2_number": ["uin2_number"],
    "zlims_id": ["zlims_id", "zlims", "ZLIMS ID"],
}

HLA_ID_COLS = ["ID", "Sample_ID", "sample_id", "ZLIMS ID", "ID_x"]

SEQ_COLS_CANDIDATES = [
    "status_coverage", "VAR_IEI_panel_table_status", "SANGER"
]

COHORT_COL = "combi_type_mcch52"

# -------- –í–∞–∫—Ü–∏–Ω—ã: –∫–æ–Ω—Ñ–∏–≥ –∞–≤—Ç–æ-–æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ --------
# –í—Å–µ —Å–ø–∏—Å–∫–∏ ‚Äî ¬´–∫–∞–Ω–¥–∏–¥–∞—Ç—ã¬ª, –±–µ—Ä—ë–º —Ç–µ, –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ–∞–ª—å–Ω–æ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö
VACC_DEFAULT_PATH = "RPB_metavac_wizard_ZLIMS_GOOD_04.08.25.xlsx"
HLA_DEFAULT_PATH = "combined_hla_table.xlsx"

# –ï–¥–∏–Ω–∞—è —Å—Ö–µ–º–∞ –ø–æ –Ω–æ–∑–æ–ª–æ–≥–∏—è–º
DISEASES = {
    "measles": {
        "title": "–ö–æ—Ä—å",
        "me_ml": "measles_ME_ml",
        "result": "measles_result",
        "sick": "measles_sick",
        "vacc_info": "measles_vaccine_info",
        "vacc_total": "measles_vaccine_totalnum",
        "noanswer": "measles_NoAnswer_coef",
    },
    "rubella": {
        "title": "–ö—Ä–∞—Å–Ω—É—Ö–∞",
        "me_ml": "rubella_ME_ml",
        "result": "rubella_result",
        "sick": "rubella_sick",
        "vacc_info": "rubella_vaccine_info",
        "vacc_total": "rubella_vaccine_totalnum",
        "noanswer": "rubella_NoAnswer_coef",
    },
    "diphtheria": {
        "title": "–î–∏—Ñ—Ç–µ—Ä–∏—è",
        "me_ml": "diphtheria_ME_ml",
        "result": "diphtheria_result",
        "sick": "diphtheria_sick",
        "vacc_info": "diphtheria_vaccine_info",
        "vacc_total": "diphtheria_vaccine_totalnum",
        "noanswer": "diphtheria_NoAnswer_coef",
    },
    "mumps": {
        "title": "–ü–∞—Ä–æ—Ç–∏—Ç",
        "me_ml": None,
        "result": "mumps_result",
        "sick": "mumps_sick",
        "vacc_info": "mumps_vaccine_info",
        "vacc_total": "mumps_vaccine_totalnum",
        "noanswer": "mumps_NoAnswer_coef",
    },
    "HAV": {
        "title": "–ì–µ–ø–∞—Ç–∏—Ç A (HAV)",
        "me_ml": None,
        "result": "HAV_result",
        "sick": "HAV_sick",
        "vacc_info": "HAV_vaccine_info",
        "vacc_total": "HAV_vaccine_totalnum",
        "noanswer": "HAV_NoAnswer_coef",
    },
    "HBV": {
        "title": "–ì–µ–ø–∞—Ç–∏—Ç B (HBV)",
        "me_ml": "HBV_antiHBsAg_ME_ml",
        "result": "HBV_antiHBsAg_result",
        "result_extra": ["HBV_HBsAg_result", "HBV_antiHBcAg_result"],  # –¥–æ–ø. –º–∞—Ä–∫–µ—Ä—ã
        "sick": "HBV_sick",
        "vacc_info": "HBV_vaccine_info",
        "vacc_total": "HBV_vaccine_totalnum",
        "noanswer": "HBV_NoAnswer_coef",
    },
}


COMBI_COLS = [
    "Combi_NoAnswer_coef", "Combi_NoAnswer_TYPE", "fail_merge_tubes"
]

VACC_ID_COLS = [
    "ZLIMS ID", "ID_x", "zlims_id", "zlims", "patient_id", "uin2", "uin2_number", "uin2_fulltxt", "ID"
]

VACC_DATE_COLS = [
    "date", "vaccination_date", "vacc_date", "dt", "–î–∞—Ç–∞ –≤–∞–∫—Ü–∏–Ω–∞—Ü–∏–∏"
]
VACC_NAME_COLS = [
    "vaccine", "vaccine_name", "vacc_name", "vaccine_product", "vaccine_brand", "–í–∞–∫—Ü–∏–Ω–∞"
]
VACC_MANUF_COLS = [
    "manufacturer", "producer", "brand", "–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å"
]
VACC_DOSE_NUM_COLS = [
    "dose", "dose_number", "dose_no", "–ù–æ–º–µ—Ä –¥–æ–∑—ã"
]
VACC_SERIES_COLS = [
    "batch", "series", "lot", "–°–µ—Ä–∏—è"
]
VACC_AE_FLAG_COLS = [
    "ae", "adverse_event", "aefi", "–ù–ü–ü–ò", "–ù–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ–µ_—è–≤–ª–µ–Ω–∏–µ", "adverse"
]
VACC_AE_TYPE_COLS = [
    "ae_type", "aefi_type", "adverse_type", "–¢–∏–ø_–ù–ü–ü–ò"
]
VACC_AE_SEV_COLS = [
    "ae_severity", "severity", "–°—Ç–µ–ø–µ–Ω—å_—Ç—è–∂–µ—Å—Ç–∏"
]


# patterns to search (case-insensitive)
PATTERNS: Dict[str, str] = {
    "disregulation": r"–¥–∏—Å—Ä–µ–≥—É–ª",  # –¥–∏—Å—Ä–µ–≥—É–ª—è—Ü–∏
    "cvid_ovin": r"(–æ–≤–∏–Ω|–æ–±—â(–∞—è|–∏–π)\s+–≤–∞—Ä–∏–∞–±–µ–ª\w*\s+–∏–º–º—É–Ω\w*\s+–Ω–µ–¥–æ—Å—Ç–∞—Ç\w*|cvid)",
    "avz_autoinfl": r"(–∞–≤–∑|–∞—É—Ç–æ–≤–æ—Å–ø–∞–ª–µ–Ω–∏\w*|–∞—É—Ç–æ–≤–æ—Å–ø–∞–ª–∏—Ç\w*)",
    "neutropenia": r"–Ω–µ–π—Ç—Ä–æ–ø–µ–Ω\w*",
    "urticaria_skin": r"(–∫—Ä–∞–ø–∏–≤–Ω–∏—Ü\w*|–∫–æ–∂–Ω\w*\s*—Å–∏–Ω–¥—Ä–æ–º\w*)",
    "atopic_derm": r"(–∞—Ç–æ–ø–∏—á–µ—Å–∫\w*.*–¥–µ—Ä–º–∞—Ç–∏—Ç|–∞—Ç–æ–ø–∏—á–µ—Å–∫\w+|–¥–µ—Ä–º–∞—Ç–∏—Ç)",
    "ige_mentioned": r"\bige\b",
    "ige_elevated": r"\bige\b.*(–ø–æ–≤—ã—à|elevat)",
    "asthma": r"–∞—Å—Ç–º\w*",
    "edema_angio": r"(–æ—Ç–µ–∫\w*|–∞–Ω–≥–∏–æ–æ—Ç–µ–∫\w*|–∫–≤–∏–Ω–∫–µ|–Ω–∞–æ|–Ω–∞—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω\w*\s*–∞–Ω–≥–∏–æ)",
    "rash": r"–≤—ã—Å—ã–ø–∞\w*",
    "arthritis_joint": r"(–∞—Ä—Ç—Ä–∏—Ç\w*|—Å—É—Å—Ç–∞–≤\w*|–∞—Ä—Ç—Ä–æ–∑\w*)",
    "anemia_thrombocytopenia": r"(–∞–Ω–µ–º–∏\w*|—Ç—Ä–æ–º–±–æ—Ü–∏—Ç–æ–ø–µ–Ω\w*)",
    "allergy_block": r"(–∞–ª–ª–µ—Ä–≥\w*|—Å–µ–Ω—Å–∏–±–∏–ª–∏–∑\w*|–ø—ã–ª—å—Ü\w*)",
    "sle": r"(–≤–æ–ª—á–∞–Ω\w*|\b—Å–∫–≤\b)",
    "behcet": r"–±–µ—Ö—á–µ—Ç\w*",
    "autoimmune": r"–∞—É—Ç–æ–∏–º–º—É–Ω\w*",
}


def pick_existing(df: pd.DataFrame, candidates: List[str]) -> List[str]:
    low = {c.lower(): c for c in df.columns}
    res = []
    for cand in candidates:
        if cand.lower() in low:
            res.append(low[cand.lower()])
    return res


def first_existing(df: pd.DataFrame, candidates: List[str]) -> str | None:
    cols = pick_existing(df, candidates)
    return cols[0] if cols else None


def pick_first_or_none(df: pd.DataFrame, candidates: List[str]) -> str | None:
    """–°–∏–Ω–æ–Ω–∏–º –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏ –∫–æ–¥–∞ –ø–æ –≤–∞–∫—Ü–∏–Ω–∞–º."""
    return first_existing(df, candidates)


def normalize_cols(df: pd.DataFrame) -> pd.DataFrame:
    df.columns = [str(c).strip() for c in df.columns]
    return df


# ======== HLA helpers ========

def normalize_allele(allele: str, level: int = 2) -> str:
    """
    'HLA-A*01:01:01' -> 'A*01' (level=1) –∏–ª–∏ 'A*01:01' (level=2).
    '-' –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å.
    """
    if not isinstance(allele, str) or allele == "-":
        return allele
    m = _re.match(r"HLA-([A-Z0-9]+)\*(\d{2})(?::(\d{2}))?", allele)
    if m:
        gene, group, protein = m.groups()
        if level == 1:
            return f"{gene}*{group}"
        elif level == 2 and protein:
            return f"{gene}*{group}:{protein}"
    return allele

def normalize_and_fill(hla_df: pd.DataFrame, level: int) -> pd.DataFrame:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö HLA-–∞–ª–ª–µ–ª–µ–π + –∑–∞–º–µ–Ω–∞ '-' –Ω–∞ —Å–æ—Å–µ–¥–Ω–∏–π –∞–ª–ª–µ–ª—å (–µ—Å–ª–∏ –µ—Å—Ç—å)."""
    df = hla_df.copy()
    gene_cols = [c for c in df.columns if "_" in str(c)]
    genes = sorted(set(c.split("_")[0] for c in gene_cols))
    for g in genes:
        c1, c2 = f"{g}_1", f"{g}_2"
        if c1 in df.columns and c2 in df.columns:
            df[c1] = df[c1].apply(lambda x: normalize_allele(x, level))
            df[c2] = df[c2].apply(lambda x: normalize_allele(x, level))
            df[c1] = df.apply(lambda r: r[c2] if r[c1] == "-" else r[c1], axis=1)
            df[c2] = df.apply(lambda r: r[c1] if r[c2] == "-" else r[c2], axis=1)
    return df

def process_hla_long(hla_df: pd.DataFrame, allele_level: int) -> pd.DataFrame:
    """
    Wide -> long: –∫–æ–ª–æ–Ω–∫–∏ ID, Gene, Allele.
    –ü–æ —á–µ–ª–æ–≤–µ–∫—É —Å–æ–∑–¥–∞—ë—Ç—Å—è –ø–æ 2 –∑–∞–ø–∏—Å–∏ –Ω–∞ –≥–µ–Ω (—É—á–∏—Ç—ã–≤–∞–µ–º –≥–æ–º–æ–∑–∏–≥–æ—Ç—É).
    """
    df = normalize_and_fill(hla_df, allele_level)
    # –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –Ω–∞–ª–∏—á–∏–µ ID
    if "ID" not in df.columns:
        raise ValueError("–í HLA-—Ç–∞–±–ª–∏—Ü–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞ ID.")
    rec = []
    gene_cols = [c for c in df.columns if "_" in str(c)]
    genes = sorted(set(c.split("_")[0] for c in gene_cols))
    for g in genes:
        c1, c2 = f"{g}_1", f"{g}_2"
        if c1 in df.columns and c2 in df.columns:
            for _, r in df[[ "ID", c1, c2 ]].iterrows():
                a1, a2 = r[c1], r[c2]
                if pd.isna(r["ID"]):
                    continue
                if a1 == a2:
                    rec.append((str(r["ID"]), g, a1))
                    rec.append((str(r["ID"]), g, a1))
                else:
                    rec.append((str(r["ID"]), g, a1))
                    rec.append((str(r["ID"]), g, a2))
    return pd.DataFrame(rec, columns=["ID","Gene","Allele"])

def counts_and_tests(hla_long: pd.DataFrame, groups_df: pd.DataFrame) -> pd.DataFrame:
    """
    –ë–∏–Ω–∞—Ä–Ω—ã–π –∏—Å—Ö–æ–¥ (Group 0/1): œá¬≤/Fisher –Ω–∞ –∫–∞–∂–¥–æ–º –∞–ª–ª–µ–ª–µ –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–≥–æ –≥–µ–Ω–∞.
    hla_long: ID, Gene, Allele
    groups_df: ID, Group (0/1)
    """
    df = hla_long.merge(groups_df[["ID","Group"]], on="ID", how="inner")
    out = []
    for g in sorted(df["Gene"].dropna().unique()):
        sub = df[df["Gene"] == g]
        # —á–∞—Å—Ç–æ—Ç—ã –Ω–æ—Å–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –ø–æ ID
        carr = (sub.groupby(["ID","Allele"]).size().reset_index()[["ID","Allele"]])
        carr["present"] = 1
        carr = carr.merge(groups_df[["ID","Group"]], on="ID", how="left").dropna(subset=["Group"])
        # –≤—Å–µ–≥–æ –ø–æ –≥—Ä—É–ø–ø–∞–º
        n_by_group = groups_df.drop_duplicates("ID")["Group"].value_counts().to_dict()
        for a in sorted(carr["Allele"].dropna().unique()):
            tab = (
                carr.assign(is_a=(carr["Allele"] == a).astype(int))
                    .groupby("Group")["is_a"].sum()
                    .reindex([0,1], fill_value=0)
            )
            a0, a1 = int(tab.get(0,0)), int(tab.get(1,0))
            n0, n1 = int(n_by_group.get(0,0)), int(n_by_group.get(1,0))
            if (a0 + a1) == 0 or n0 == 0 or n1 == 0:
                continue
            cont = [[a1, n1 - a1],[a0, n0 - a0]]
            try:
                if min(min(cont)) < 5:
                    _, p = fisher_exact(cont)
                    test = "Fisher"
                else:
                    chi2, p, _, _ = chi2_contingency(cont)
                    test = "Chi2"
            except Exception:
                continue
            freq1 = a1 / n1 if n1 else 0.0
            freq0 = a0 / n0 if n0 else 0.0
            out.append({
                "Gene": g, "Allele": a,
                "count_res1": a1, "count_res0": a0,
                "n_res1": n1, "n_res0": n0,
                "freq_res1": freq1, "freq_res0": freq0,
                "delta_freq": freq1 - freq0,
                "test": test, "p_value": p,
            })
    res = pd.DataFrame(out)
    if res.empty:
        return res
    reject, pcor, _, _ = multipletests(res["p_value"], method="fdr_bh")
    res["p_fdr_bh"] = pcor
    res["signif_fdr"] = reject
    return res.sort_values(["p_fdr_bh","p_value","Gene","Allele"])


def st_bar_chart_safe(obj):
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ st.bar_chart:
    - –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç IntervalIndex (–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏) –≤ —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –º–µ—Ç–∫–∏,
      —á—Ç–æ–±—ã Altair/Streamlit –Ω–µ –ø–∞–¥–∞–ª–∏ —Å –æ—à–∏–±–∫–æ–π —Å—Ö–µ–º—ã.
    """
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ DataFrame
    if isinstance(obj, pd.Series):
        df = obj.to_frame(name=obj.name or "value")
    elif isinstance(obj, pd.DataFrame):
        df = obj.copy()
    else:
        df = pd.DataFrame(obj)

    try:
        # –°–ª—É—á–∞–π: –∏–Ω–¥–µ–∫—Å ‚Äî IntervalIndex
        if isinstance(df.index, pd.IntervalIndex):
            df = df.reset_index().rename(columns={"index": "bin"})
            df["bin"] = df["bin"].astype(str)
            df = df.set_index("bin")
        else:
            # –°–ª—É—á–∞–π: –∏–Ω–¥–µ–∫—Å ‚Äî MultiIndex (–∫–æ—Ä—Ç–µ–∂–∏) ‚Üí —Å–∫–ª–µ–∏–≤–∞–µ–º –≤ —Å—Ç—Ä–æ–∫—É
            if isinstance(df.index, pd.MultiIndex):
                df.index = df.index.map(lambda x: " | ".join(map(str, x)))
                df.index.name = df.index.name or "bin"

            if len(df.index) and isinstance(df.index[0], pd.Interval):
                df.index = df.index.map(str)
    except Exception:
        # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π: –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫, –ø—Ä–æ—Å—Ç–æ —Å—Ç—Ä–æ–∫–∏–∑—É–µ–º –∏–Ω–¥–µ–∫—Å
        try:
            df.index = df.index.map(str)
        except Exception:
            pass

    st.bar_chart(df)


############################################
# HLA –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è ‚Äî –∫–∞–∫ –≤ —ç—Ç–∞–ª–æ–Ω–Ω–æ–º –∫–æ–¥–µ  #
############################################
def normalize_allele(allele: str, level: int = 2) -> str:
    """
    –†–æ–≤–Ω–æ –∫–∞–∫ –≤ —ç—Ç–∞–ª–æ–Ω–µ:
      - —Å—Ç—Ä–æ–∫–∞ –¥–æ–ª–∂–Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —à–∞–±–ª–æ–Ω—É 'HLA-GENE*XX(:YY)?'
      - level=1 -> 'GENE*XX'
      - level=2 -> 'GENE*XX:YY' (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å YY)
      - '-' –∏ –≤—Å—ë –Ω–µ—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
    """
    if not isinstance(allele, str) or allele == "-":
        return allele
    pattern = r"HLA-([A-Z0-9]+)\*(\d{2})(?::(\d{2}))?"
    match = re.match(pattern, allele)
    if match:
        gene, group, protein = match.groups()
        if level == 1:
            return f"{gene}*{group}"
        elif level == 2 and protein:
            return f"{gene}*{group}:{protein}"
    return allele

def normalize_and_fill(df: pd.DataFrame, level: int) -> pd.DataFrame:
    """
    –†–æ–≤–Ω–æ –∫–∞–∫ –≤ —ç—Ç–∞–ª–æ–Ω–µ:
      - –ø—Ä–∏–º–µ–Ω—è–µ–º normalize_allele –∫ –∫–∞–∂–¥–æ–π –∞–ª–ª–µ–ª—å–Ω–æ–π –∫–æ–ª–æ–Ω–∫–µ *_1 / *_2
      - –ø—Ä–æ—á–µ—Ä–∫–∏ '-' –∑–∞–º–µ–Ω—è–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ–º –∏–∑ —Å–æ—Å–µ–¥–Ω–µ–π –∫–æ–ª–æ–Ω–∫–∏ –ø–∞—Ä—ã
    """
    df_clean = df.copy()
    gene_columns = [col for col in df.columns if "_" in str(col)]
    gene_prefixes = sorted(set(col.split("_")[0] for col in gene_columns))

    for gene in gene_prefixes:
        col1, col2 = f"{gene}_1", f"{gene}_2"
        if col1 in df_clean and col2 in df_clean:
            df_clean[col1] = df_clean[col1].apply(lambda x: normalize_allele(x, level))
            df_clean[col2] = df_clean[col2].apply(lambda x: normalize_allele(x, level))
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ—á–µ—Ä–∫–∏ –∑–Ω–∞—á–µ–Ω–∏–µ–º –∏–∑ —Å–æ—Å–µ–¥–Ω–µ–π –∫–æ–ª–æ–Ω–∫–∏
            df_clean[col1] = df_clean.apply(
                lambda row: row[col2] if row[col1] == "-" else row[col1], axis=1)
            df_clean[col2] = df_clean.apply(
                lambda row: row[col1] if row[col2] == "-" else row[col2], axis=1)
    return df_clean

def process_hla_long(df: pd.DataFrame, level: int) -> pd.DataFrame:
    """
    long-—Ç–∞–±–ª–∏—Ü–∞ –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞: (ID, Gene, Allele)
    –ü–æ–≤–µ–¥–µ–Ω–∏–µ –ø–æ –∞–ª–ª–µ–ª—è–º —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —ç—Ç–∞–ª–æ–Ω–æ–º:
      - normalize_and_fill
      - –¥—É–±–ª–∏—Ä—É–µ–º –∞–ª–ª–µ–ª—å –ø—Ä–∏ –≥–æ–º–æ–∑–∏–≥–æ—Ç–Ω–æ—Å—Ç–∏
      - –∑–∞—Ç–µ–º –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º '-' –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    –û–∂–∏–¥–∞–µ—Ç—Å—è, —á—Ç–æ –≤ df —É–∂–µ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∞ 'ID' (—Å—Ç—Ä–æ–∫–∞).
    """
    if "ID" not in df.columns:
        raise ValueError("–û–∂–∏–¥–∞–µ—Ç—Å—è –∫–æ–ª–æ–Ω–∫–∞ 'ID' –≤ HLA-—Ç–∞–±–ª–∏—Ü–µ.")

    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–∞—Ä—ã *_1/*_2
    df_norm = normalize_and_fill(df, level)

    records = []
    gene_columns = [col for col in df_norm.columns if "_" in str(col)]
    gene_prefixes = sorted(set(col.split("_")[0] for col in gene_columns))

    for _, row in df_norm.iterrows():
        pid = str(row["ID"])
        for gene in gene_prefixes:
            col1, col2 = f"{gene}_1", f"{gene}_2"
            if col1 not in df_norm.columns or col2 not in df_norm.columns:
                continue
            a1, a2 = row[col1], row[col2]
            if a1 == a2:
                # –≥–æ–º–æ–∑–∏–≥–æ—Ç–∞ ‚Äî –¥–≤–µ –∫–æ–ø–∏–∏ –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ –∞–ª–ª–µ–ª—è
                records.append((pid, gene, a1))
                records.append((pid, gene, a1))
            else:
                records.append((pid, gene, a1))
                records.append((pid, gene, a2))

    out = pd.DataFrame(records, columns=["ID", "Gene", "Allele"])
    # –ß—Ç–æ–±—ã '-' –Ω–µ –ø–æ–ø–∞–¥–∞–ª–∏ –≤ —Ç–µ—Å—Ç—ã
    out = out[out["Allele"] != "-"]
    return out

def coalesce_first_nonnull(df: pd.DataFrame, cols: list[str]) -> pd.Series | None:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–µ—Ä–∏—é ‚Äî –ø–µ—Ä–≤—ã–π –Ω–µ–ø—É—Å—Ç–æ–π ID –ø–æ —Å–ø–∏—Å–∫—É –∫–æ–ª–æ–Ω–æ–∫-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤.
    –ü–æ–ª–µ–∑–Ω–æ, –µ—Å–ª–∏ ID —Ä–∞–∑–º–∞–∑–∞–Ω –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –ø–æ–ª—è–º.
    """
    present = [c for c in cols if c in df.columns]
    if not present:
        return None
    s = pd.Series(index=df.index, dtype="object")
    for c in present:
        v = df[c].astype("string").str.strip()
        s = s.fillna(v.where(v.notna() & (v != "")))
    # –ø–æ–¥—á–∏—Å—Ç–∏–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
    s = s.where(s.notna() & (s != ""))
    return s


def concat_text_row(row: pd.Series, text_cols: List[str]) -> str:
    parts = []
    for c in text_cols:
        val = row.get(c, None)
        if pd.notna(val):
            parts.append(str(val))
    return " | ".join(parts).lower()

def has_nonempty(row: pd.Series, cols: List[str]) -> bool:
    for c in cols:
        if c in row and pd.notna(row[c]) and str(row[c]).strip() != "":
            return True
    return False

def mark_patterns(df: pd.DataFrame, text_cols: List[str]) -> pd.DataFrame:
    if not text_cols:
        for key in PATTERNS:
            df[key] = False
        return df
    texts = df[text_cols].astype(str).agg(" | ".join, axis=1).str.lower()
    for key, pat in PATTERNS.items():
        df[key] = texts.str.contains(pat, regex=True, na=False, case=False)
    return df

def compute_completeness(df: pd.DataFrame) -> pd.Series:
    # IDs: require (zlims_id) AND (uin2_number OR uin2_fulltxt)
    id_zlims = first_existing(df, ID_COLS["zlims_id"])
    id_uin_num = first_existing(df, ID_COLS["uin2_number"])
    id_uin_txt = first_existing(df, ID_COLS["uin2_fulltxt"])

    has_zlims = df[id_zlims].notna() & (df[id_zlims].astype(str).str.strip() != "") if id_zlims else False
    has_uin_any = False
    if id_uin_num:
        has_uin_any = df[id_uin_num].notna() & (df[id_uin_num].astype(str).str.strip() != "")
    if id_uin_txt:
        u = df[id_uin_txt].notna() & (df[id_uin_txt].astype(str).str.strip() != "")
        has_uin_any = (has_uin_any | u) if isinstance(has_uin_any, pd.Series) else u

    # Diagnosis info present if any of these non-empty
    diag_cols = pick_existing(df, ["IUIS_classification", "combi_diganosis_mcch52", "clinical_discuss"])
    has_diag = df[diag_cols].astype(str).apply(lambda s: s.str.strip() != "", axis=0).any(axis=1) if diag_cols else False

    # Sequencing info present if any of these non-empty
    seq_cols = pick_existing(df, SEQ_COLS_CANDIDATES)
    has_seq = df[seq_cols].astype(str).apply(lambda s: s.str.strip() != "", axis=0).any(axis=1) if seq_cols else False

    complete = has_zlims & has_uin_any & has_diag & has_seq
    return complete.fillna(False) if isinstance(complete, pd.Series) else pd.Series([False] * len(df))

@st.cache_data(show_spinner=False)
def read_xlsx(src):
    return pd.read_excel(src)

# ----------------------
# Load data
# ----------------------

st.sidebar.header("–î–∞–Ω–Ω—ã–µ")
uploaded = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel-—Ñ–∞–π–ª (.xlsx) c —Ç–∞–±–ª–∏—Ü–µ–π", type=["xlsx"])
default_path = "PID_AID_phenotypes_13.08.25.xlsx"

# –í–∞–∫—Ü–∏–Ω—ã: –æ—Ç–¥–µ–ª—å–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫ (–ø–æ –∂–µ–ª–∞–Ω–∏—é), –∏–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—É—Ç—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
vacc_uploaded = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –≤–∞–∫—Ü–∏–Ω–∞–º–∏ (.xlsx)", type=["xlsx"], key="vacc_upl")
vacc_default_path = VACC_DEFAULT_PATH


if uploaded is not None:
    df = pd.read_excel(uploaded)
elif default_path:
    try:
        df = pd.read_excel(default_path)
        st.sidebar.info("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ñ–∞–π–ª –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: PID_AID_phenotypes_13.08.25.xlsx")
    except Exception as e:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {e}")
        st.stop()
else:
    st.stop()

st.title("PID/AID ‚Äî –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ")

# normalize columns (strip)
df = normalize_cols(df)

# cohort selector
if COHORT_COL in df.columns:
    cohorts = ["(–≤—Å–µ)"] + sorted([str(x) for x in df[COHORT_COL].dropna().unique()])
    picked = st.sidebar.selectbox("–ö–æ–≥–æ—Ä—Ç–∞ (combi_type_mcch52)", cohorts, index=0)
    if picked != "(–≤—Å–µ)":
        df = df[df[COHORT_COL].astype(str) == picked]
else:
    st.sidebar.warning("–ö–æ–ª–æ–Ω–∫–∞ 'combi_type_mcch52' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ ‚Äî —Ñ–∏–ª—å—Ç—Ä –ø–æ –∫–æ–≥–æ—Ä—Ç–µ –æ—Ç–∫–ª—é—á—ë–Ω.")

# completeness
complete_mask = compute_completeness(df)
mode = st.sidebar.radio("–ü–æ–ª–Ω–æ—Ç–∞ –¥–∞–Ω–Ω—ã—Ö", ["–í—Å–µ", "–¢–æ–ª—å–∫–æ –ø–æ–ª–Ω—ã–µ (ID + –¥–∏–∞–≥–Ω–æ–∑ + —Å–µ–∫–≤–µ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ)", "–¢–æ–ª—å–∫–æ –Ω–µ–ø–æ–ª–Ω—ã–µ"], index=0)
if mode != "–í—Å–µ":
    if mode.startswith("–¢–æ–ª—å–∫–æ –ø–æ–ª–Ω—ã–µ"):
        df = df.loc[complete_mask]
    else:
        df = df.loc[~complete_mask]

# build text columns to search
text_cols = pick_existing(df, TEXT_COLS_CANDIDATES)

# mark presence columns
df_marked = df.copy()
df_marked = mark_patterns(df_marked, text_cols)

presence_cols = list(PATTERNS.keys())
binary_table = df_marked[presence_cols].copy().astype(bool)
# attach IDs for reference (best-effort)
id_show_cols = pick_existing(df_marked, ["ID", "uin2_number", "uin2_fulltxt", "zlims_id", "ZLIMS ID", "ID_x"])
binary_table = pd.concat([df_marked[id_show_cols], binary_table], axis=1) if id_show_cols else binary_table

# ----------------------
# Tabs
# ----------------------
tab1, tab2, tab3 = st.tabs([
    "üß¨ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ",
    "üíâ –í–∞–∫—Ü–∏–Ω—ã",
    "üß¨‚áÑüíâ HLA √ó Measles (–±–∏–Ω–∞—Ä–Ω—ã–π)",
])

# –æ—Ç–¥–µ–ª—å–Ω–∞—è –≤–∫–ª–∞–¥–∫–∞ –¥–ª—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∞–Ω—Ç–∏—Ç–µ–ª
tab4 = st.container()

with tab1:
    st.subheader("–°–≤–æ–¥–∫–∞ –ø–æ –º–µ—Ç–∫–∞–º (–≤ —Ç–µ–∫—É—â–µ–π –≤—ã–±–æ—Ä–∫–µ)")
    counts = df_marked[presence_cols].sum().sort_values(ascending=False).rename("count").to_frame()
    st.dataframe(counts)

    # === –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö ===
    st.markdown("### –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º")
    # 1) –°—Ç–æ–ª–±—á–∞—Ç–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ –ø–æ —Å—É–º–º–∞—Ä–Ω—ã–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è–º
    try:
        st_bar_chart_safe(counts)
    except Exception:
        st.write("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å bar chart –¥–ª—è —Å–≤–æ–¥–∫–∏.")

    # 2) –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–∏—Å–ª–∞ –º–µ—Ç–æ–∫ –Ω–∞ –ø–∞—Ü–∏–µ–Ω—Ç–∞ (—Å–∫–æ–ª—å–∫–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —É –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏)
    try:
        matches_per_row = df_marked[presence_cols].astype(bool).sum(axis=1)
        st.markdown("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –Ω–∞ –ø–∞—Ü–∏–µ–Ω—Ç–∞**")
        # –ø—Ä–µ–≤—Ä–∞—Ç–∏–º –≤ —á–∞—Å—Ç–æ—Ç—ã
        hist_df = matches_per_row.value_counts().sort_index().rename_axis("num_flags").to_frame("patients")
        st_bar_chart_safe(hist_df)
    except Exception:
        st.write("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ –ø–∞—Ü–∏–µ–Ω—Ç–∞–º.")

    st.markdown("### –¢–∞–±–ª–∏—Ü–∞ ¬´–µ—Å—Ç—å/–Ω–µ—Ç¬ª –ø–æ –ø–∞—Ü–∏–µ–Ω—Ç–∞–º")
    st.dataframe(binary_table)

    # === –û—Ç–ª–∞–¥–∫–∞: –ø–∞—Ü–∏–µ–Ω—Ç—ã –±–µ–∑ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π ===
    st.markdown("### –ü–∞—Ü–∏–µ–Ω—Ç—ã –±–µ–∑ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π (–≤—Å–µ –º–µ—Ç–∫–∏ = False)")
    try:
        no_flags_mask = ~df_marked[presence_cols].any(axis=1)
        df_no_flags = df.loc[no_flags_mask]
        if not df_no_flags.empty:
            st.dataframe(df_no_flags)
            st.caption(f"–ü–æ–∫–∞–∑–∞–Ω–æ {len(df_no_flags)} —Å—Ç—Ä–æ–∫ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã –±–µ–∑ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π.")
        else:
            st.info("–í—Å–µ –ø–∞—Ü–∏–µ–Ω—Ç—ã –∏–º–µ—é—Ç —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –º–µ—Ç–∫—É.")
    except Exception as e:
        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã—á–∏—Å–ª–∏—Ç—å –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤ –±–µ–∑ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π: {e}")

    # === –≠–∫—Å–ø–æ—Ä—Ç —Ç–∞–±–ª–∏—Ü ===
    st.markdown("### –≠–∫—Å–ø–æ—Ä—Ç —Ç–∞–±–ª–∏—Ü")
    def to_csv_bytes(df: pd.DataFrame) -> bytes:
        return df.to_csv(index=False).encode("utf-8")

    def to_xlsx_bytes(df: pd.DataFrame) -> bytes:
        bio = io.BytesIO()
        with pd.ExcelWriter(bio, engine="openpyxl") as writer:
            df.to_excel(writer, index=False, sheet_name="data")
        bio.seek(0)
        return bio.read()

    col_a, col_b, col_c, col_d = st.columns(4)
    with col_a:
        st.download_button(
            label="‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å '–µ—Å—Ç—å/–Ω–µ—Ç' (CSV)",
            data=to_csv_bytes(binary_table),
            file_name="binary_table.csv",
            mime="text/csv",
        )
    with col_b:
        st.download_button(
            label="‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å '–µ—Å—Ç—å/–Ω–µ—Ç' (XLSX)",
            data=to_xlsx_bytes(binary_table),
            file_name="binary_table.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )
    with col_c:
        st.download_button(
            label="‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å —Å–≤–æ–¥–∫—É (CSV)",
            data=to_csv_bytes(counts.reset_index()),
            file_name="summary_counts.csv",
            mime="text/csv",
        )
    with col_d:
        st.download_button(
            label="‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å —Å–≤–æ–¥–∫—É (XLSX)",
            data=to_xlsx_bytes(counts.reset_index()),
            file_name="summary_counts.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

    st.markdown("### –û–ø–∏—Å–∞–Ω–∏–µ –ø–æ–ª–µ–π")

    # === –ö—Ä—É–≥–æ–≤—ã–µ –¥–∏–∞–≥—Ä–∞–º–º—ã –ø–æ –¥–∏–∞–≥–Ω–æ–∑–∞–º ===
    st.markdown("### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–∏–∞–≥–Ω–æ–∑–∞–º –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è–º")
    import matplotlib.pyplot as plt

    def plot_pie(series: pd.Series, title: str):
        vc = series.dropna().astype(str).value_counts()
        if vc.empty:
            st.info(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {title}")
            return
        # –æ–≥—Ä–∞–Ω–∏—á–∏–º —Ç–æ–ø-10, –æ—Å—Ç–∞–ª—å–Ω–æ–µ —Å—É–º–º–∏—Ä—É–µ–º –≤ 'Other'
        top10 = vc.head(10)
        if len(vc) > 10:
            top10.loc["Other"] = vc.iloc[10:].sum()
        fig, ax = plt.subplots()
        ax.pie(top10.values, labels=top10.index, autopct="%1.1f%%", startangle=90, counterclock=False)
        ax.axis("equal")
        ax.set_title(title)
        st.pyplot(fig)

    if "combi_diganosis_mcch52" in df.columns:
        plot_pie(df["combi_diganosis_mcch52"], "combi_diganosis_mcch52")
    else:
        st.warning("–ö–æ–ª–æ–Ω–∫–∞ combi_diganosis_mcch52 –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

    if "IUIS_classification" in df.columns:
        plot_pie(df["IUIS_classification"], "IUIS_classification")
    else:
        st.warning("–ö–æ–ª–æ–Ω–∫–∞ IUIS_classification –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

    st.markdown(
        """
- **disregulation** ‚Äî —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –¥–∏—Å—Ä–µ–≥—É–ª—è—Ü–∏–∏ –∏–º–º—É–Ω–∏—Ç–µ—Ç–∞
- **cvid_ovin** ‚Äî –û–í–ò–ù / CVID
- **avz_autoinfl** ‚Äî –ê–í–ó / –∞—É—Ç–æ–≤–æ—Å–ø–∞–ª–µ–Ω–∏–µ
- **neutropenia** ‚Äî –Ω–µ–π—Ç—Ä–æ–ø–µ–Ω–∏—è
- **urticaria_skin** ‚Äî –∫—Ä–∞–ø–∏–≤–Ω–∏—Ü–∞ / –∫–æ–∂–Ω—ã–π —Å–∏–Ω–¥—Ä–æ–º
- **atopic_derm** ‚Äî –∞—Ç–æ–ø–∏—á–µ—Å–∫–∏–π –¥–µ—Ä–º–∞—Ç–∏—Ç / –∞—Ç–æ–ø–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ—è–≤–ª–µ–Ω–∏—è / –¥–µ—Ä–º–∞—Ç–∏—Ç
- **ige_mentioned** ‚Äî —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ IgE
- **ige_elevated** ‚Äî —è–≤–Ω–æ–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –ø–æ–≤—ã—à–µ–Ω–∏—è IgE
- **asthma** ‚Äî –∞—Å—Ç–º–∞
- **edema_angio** ‚Äî –æ—Ç–µ–∫–∏, –∞–Ω–≥–∏–æ–æ—Ç–µ–∫–∏, –ö–≤–∏–Ω–∫–µ, –ù–ê–û
- **rash** ‚Äî –≤—ã—Å—ã–ø–∞–Ω–∏—è
- **arthritis_joint** ‚Äî –∞—Ä—Ç—Ä–∏—Ç/–∞—Ä—Ç—Ä–æ–∑/—Å—É—Å—Ç–∞–≤–Ω—ã–µ
- **anemia_thrombocytopenia** ‚Äî –∞–Ω–µ–º–∏–∏ –∏ —Ç—Ä–æ–º–±–æ—Ü–∏—Ç–æ–ø–µ–Ω–∏–∏
- **allergy_block** ‚Äî –∞–ª–ª–µ—Ä–≥–∏—è, —Å–µ–Ω—Å–∏–±–∏–ª–∏–∑–∞—Ü–∏—è, —Ä–∏–Ω–∏—Ç, –ø—ã–ª—å—Ü–µ–≤–∞—è
- **sle** ‚Äî –°–ö–í / —Å–∏—Å—Ç–µ–º–Ω–∞—è –∫—Ä–∞—Å–Ω–∞—è –≤–æ–ª—á–∞–Ω–∫–∞
- **behcet** ‚Äî –±–æ–ª–µ–∑–Ω—å –ë–µ—Ö—á–µ—Ç–∞
- **autoimmune** ‚Äî —É–ø–æ–º–∏–Ω–∞–Ω–∏—è ¬´–∞—É—Ç–æ–∏–º–º—É–Ω-¬ª
"""
    )

    st.caption("–ü–æ–¥—Å—á—ë—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω –ø–æ —Å–≤–æ–±–æ–¥–Ω–æ–º—É —Ç–µ–∫—Å—Ç—É –∏–∑ –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏—Ö –∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏—Ö –∫–æ–ª–æ–Ω–æ–∫. –†–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–π –ø–æ–∏—Å–∫ –ø–æ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º.")



# ----------------------
# –í–∫–ª–∞–¥–∫–∞: –í–∞–∫—Ü–∏–Ω—ã
# ----------------------
with tab2:
    st.subheader("–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–æ –≤–∞–∫—Ü–∏–Ω–∞—Ü–∏—è–º")

    # === –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ –≤–∞–∫—Ü–∏–Ω–∞—Ü–∏—è—Ö ===
    try:
        if vacc_uploaded is not None:
            vacc_df = pd.read_excel(vacc_uploaded)
            st.info("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å –≤–∞–∫—Ü–∏–Ω–∞–º–∏.")
        else:
            vacc_df = pd.read_excel(vacc_default_path)
            st.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ñ–∞–π–ª –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {vacc_default_path}")
    except Exception as e:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª —Å –≤–∞–∫—Ü–∏–Ω–∞–º–∏: {e}")
        st.stop()
    vacc_df = normalize_cols(vacc_df.copy())

    # === –ê–≤—Ç–æ-–¥–µ—Ç–µ–∫—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ ===
    col_id   = pick_first_or_none(vacc_df, VACC_ID_COLS)
    col_date = pick_first_or_none(vacc_df, VACC_DATE_COLS)


    # === –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –¥–∞—Ç—ã ===
    if col_date and pd.api.types.is_string_dtype(vacc_df[col_date]):
        with pd.option_context("mode.chained_assignment", None):
            vacc_df[col_date] = pd.to_datetime(vacc_df[col_date], errors="coerce")

    # === –°–≤–æ–¥–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ ===
    st.markdown("### –°–≤–æ–¥–∫–∞")
    total_rows = len(vacc_df)
    unique_patients = vacc_df[col_id].nunique() if col_id else None


    m = []
    m.append(("–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π (–¥–æ–∑)", total_rows))
    if unique_patients is not None:
        m.append(("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤", unique_patients))
    metrics_df = pd.DataFrame(m, columns=["metric", "value"])
    st.dataframe(metrics_df, hide_index=True)

    # === –î–µ–º–æ–≥—Ä–∞—Ñ–∏—è ===
    st.markdown("### –î–µ–º–æ–≥—Ä–∞—Ñ–∏—è")
    for col in ["age", "sex", "cohort_region", "test_tube", "date_birth"]:
        if col in vacc_df.columns:
            s = vacc_df[col]
            if pd.api.types.is_numeric_dtype(s):
                med = pd.to_numeric(s, errors="coerce").median()
                st.write(f"**{col}** ‚Äî –º–µ–¥–∏–∞–Ω–∞: {med:.1f}")
            else:
                vc = s.astype(str).str.strip().replace({"": pd.NA}).dropna().value_counts().head(15)
                if not vc.empty:
                    st.dataframe(vc.rename_axis(col).to_frame("count"))
                    try:
                        st_bar_chart_safe(vc.rename_axis(col).to_frame("count"))
                    except Exception:
                        pass

    # === –°–µ–∫–≤–µ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ / —Ç–µ—Ö–º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ ===
    st.markdown("### –°–µ–∫–≤–µ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ / —Ç–µ—Ö–º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ")
    for col in ["–ü—Ä–æ–µ–∫—Ç","–ü–ª–∞—Ç—Ñ–æ—Ä–º—ã","–ß—Ç–µ–Ω–∏—è","Cov","–ì–µ–Ω. –ü–æ—Ä—Ç—Ä–µ—Ç","–í—Ç–æ—Ä. –ù–∞—Ö–æ–¥–∫–∏","–†–µ—Ü. –ù–æ—Å–∏—Ç.",
                "–ú–µ–¥. –ù–∞—Ö–æ–¥–∫–∏","–ú–µ–¥. –°—Ç–∞—Ç.","–ü–æ–ª/ –£–ê–ü","–î—É–±–ª–∏/ –†–æ–¥—Å—Ç–≤–æ","chr CNV","–ì–∞–ø–ª–æ–≥—Ä—É–ø–ø—ã",
                "DNB","–°—Ç–∞—Ç—É—Å","IGV","–î–∞—Ç–∞ –æ–±—Å—á–µ—Ç–∞","–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"]:
        if col in vacc_df.columns:
            s = vacc_df[col]
            if pd.api.types.is_numeric_dtype(s):
                try:
                    st.metric(col, f"{pd.to_numeric(s, errors='coerce').median():.0f}")
                except Exception:
                    st.metric(col, "‚Äî")
            else:
                vc = s.astype(str).str.strip().replace({"": pd.NA}).dropna().value_counts().head(15)
                if not vc.empty:
                    st.dataframe(vc.rename_axis(col).to_frame("count"))
                    try:
                        st_bar_chart_safe(vc.rename_axis(col).to_frame("count"))
                    except Exception:
                        pass

    # === –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–ª–∞–≥–∏ ===
    st.markdown("### –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–ª–∞–≥–∏")
    for c in ["Combi_NoAnswer_coef", "Combi_NoAnswer_TYPE", "fail_merge_tubes"]:
        if c in vacc_df.columns:
            s = vacc_df[c]
            if not pd.api.types.is_bool_dtype(s):
                s = s.astype(str).str.lower().isin(["1","true","yes","–¥–∞","y","–∏—Å—Ç–∏–Ω–∞"])
            st.write(f"**{c}** ‚Äî –¥–æ–ª—è: {float(s.mean()):.1%}")

    # === –ù–æ–∑–æ–ª–æ–≥–∏–∏ ===
    st.markdown("### –ù–æ–∑–æ–ª–æ–≥–∏–∏")
    def _clean(s): return s.astype(str).str.strip().replace({"": pd.NA})
    def _num(s): return pd.to_numeric(s, errors="coerce")
    def _bool(s):
        if pd.api.types.is_bool_dtype(s): return s.fillna(False)
        return _clean(s).str.lower().isin(["1","true","yes","–¥–∞","y","–∏—Å—Ç–∏–Ω–∞"])

    for key, meta in DISEASES.items():
        st.markdown(f"#### {meta['title']}")
        me_col = meta.get("me_ml")
        res_col = meta.get("result")
        sick_col = meta.get("sick")
        info_col = meta.get("vacc_info")
        total_col = meta.get("vacc_total")
        na_col = meta.get("noanswer")
        extra = [c for c in meta.get("result_extra", []) if c in vacc_df.columns]

        c1, c2, c3, c4 = st.columns(4)
        with c1: st.metric("–°—Ç—Ä–æ–∫", f"{len(vacc_df):,}".replace(",", " "))
        with c2:
            if col_id:
                st.metric("–ü–∞—Ü–∏–µ–Ω—Ç–æ–≤", f"{vacc_df[col_id].nunique():,}".replace(",", " "))
            else:
                st.metric("–ü–∞—Ü–∏–µ–Ω—Ç–æ–≤", "‚Äî")
        with c3:
            if sick_col in vacc_df.columns:
                st.metric("–ë–æ–ª–µ–ª", f"{float(_bool(vacc_df[sick_col]).mean()):.1%}")
            else:
                st.metric("–ë–æ–ª–µ–ª","‚Äî")
        with c4:
            if na_col in vacc_df.columns:
                st.metric("–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞", f"{float(_bool(vacc_df[na_col]).mean()):.1%}")
            else:
                st.metric("–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞","‚Äî")

        if res_col in vacc_df.columns:
            vc = _clean(vacc_df[res_col]).dropna().value_counts()
            if not vc.empty:
                st.dataframe(vc.rename_axis(res_col).to_frame("count"))
                try:
                    st_bar_chart_safe(vc.rename_axis(res_col).to_frame("count"))
                except Exception:
                    pass

        for c in extra:
            vc = _clean(vacc_df[c]).dropna().value_counts()
            if not vc.empty:
                st.dataframe(vc.rename_axis(c).to_frame("count"))
                try:
                    st_bar_chart_safe(vc.rename_axis(c).to_frame("count"))
                except Exception:
                    pass

        if me_col and me_col in vacc_df.columns:
            vals = _num(vacc_df[me_col]).dropna()
            if not vals.empty:
                try:
                    bins = pd.qcut(vals[vals >= 0], q=min(20, max(5, int(len(vals)**0.5))), duplicates="drop")
                    hist = bins.value_counts().sort_index().rename_axis("bin").to_frame("count")
                except Exception:
                    hist = pd.cut(vals, bins=20).value_counts().sort_index().rename_axis("bin").to_frame("count")
                st_bar_chart_safe(hist)
            else:
                st.info("–ù–µ—Ç —á–∏—Å–ª–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π —Ç–∏—Ç—Ä–æ–≤ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã.")

        if info_col in vacc_df.columns:
            vc = _clean(vacc_df[info_col]).dropna().value_counts()
            if not vc.empty:
                st.dataframe(vc.rename_axis(info_col).to_frame("count"))
                try:
                    st_bar_chart_safe(vc.rename_axis(info_col).to_frame("count"))
                except Exception:
                    pass

        if total_col in vacc_df.columns:
            doses = _num(vacc_df[total_col]).fillna(0).astype(int)
            vc = doses.value_counts().sort_index().rename_axis("doses").to_frame("patients")
            st.dataframe(vc)
            try:
                st_bar_chart_safe(vc)
            except Exception:
                pass

        with st.expander("–°—ã—Ä—ã–µ –ø–æ–ª—è –ø–æ –Ω–æ–∑–æ–ª–æ–≥–∏–∏"):
            show = [col_id] if col_id else []
            show += [x for x in [me_col, res_col, sick_col, info_col, total_col, na_col] if x]
            show += extra
            show = [c for c in show if c in vacc_df.columns]
            if show:
                st.dataframe(vacc_df[show].head(200))
            else:
                st.write("–ù–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.")


    # === –î–æ–∑—ã –Ω–∞ –ø–∞—Ü–∏–µ–Ω—Ç–∞ ===
    st.markdown("### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–∏—Å–ª–∞ –¥–æ–∑ –Ω–∞ –ø–∞—Ü–∏–µ–Ω—Ç–∞")
    if col_id:
        doses_per_patient = (
            vacc_df.groupby(col_id)
                   .size()
                   .rename("doses")
                   .reset_index()
        )
        st.dataframe(doses_per_patient.head(100))
        try:
            # —Å—Ç—Ä–æ–∏–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –¥–æ–∑
            hist = doses_per_patient["doses"].value_counts().sort_index().rename_axis("doses").to_frame("patients")
            st_bar_chart_safe(hist)
        except Exception:
            pass
    else:
        st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ ID –ø–∞—Ü–∏–µ–Ω—Ç–∞ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –±–ª–æ–∫ —Å –¥–æ–∑–∞–º–∏ –Ω–∞ –ø–∞—Ü–∏–µ–Ω—Ç–∞.")


    # === –≠–∫—Å–ø–æ—Ä—Ç ===
    st.markdown("### –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤–∞–∫—Ü–∏–Ω–∞—Ü–∏—è–º")
    def to_csv_bytes(df: pd.DataFrame) -> bytes:
        return df.to_csv(index=False).encode("utf-8")
    def to_xlsx_bytes(df: pd.DataFrame) -> bytes:
        bio = io.BytesIO()
        with pd.ExcelWriter(bio, engine="openpyxl") as writer:
            df.to_excel(writer, index=False, sheet_name="data")
        bio.seek(0)
        return bio.read()

    col_va, col_vb = st.columns(2)
    with col_va:
        st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ (CSV)", data=to_csv_bytes(vacc_df), file_name="vaccinations_raw.csv", mime="text/csv")
    with col_vb:
        st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ (XLSX)", data=to_xlsx_bytes(vacc_df), file_name="vaccinations_raw.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")


#####################
# Tab3: HLA √ó Measles
#####################
with tab3:
    st.subheader("–ê—Å—Å–æ—Ü–∏–∞—Ü–∏–∏ HLA ‚ÜîÔ∏é –∞–Ω—Ç–∏—Ç–µ–ª–∞ –∫ –∫–æ—Ä–∏ (measles)")
    # –ó–∞–≥—Ä—É–∑—á–∏–∫ HLA
    hla_uploaded = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ HLA-—Ç–∞–±–ª–∏—Ü—É (.xlsx)", type=["xlsx"], key="hla_upl")
    try:
        if hla_uploaded is not None:
            hla_df = read_xlsx(hla_uploaded)
            st.info("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π HLA-—Ñ–∞–π–ª.")
        else:
            hla_df = read_xlsx(HLA_DEFAULT_PATH)
            st.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è HLA-—Ñ–∞–π–ª –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {HLA_DEFAULT_PATH}")
    except Exception as e:
        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å HLA: {e}")
        st.stop()
    hla_df = normalize_cols(hla_df.copy())

    # ===== –Ø–í–ù–û –∑–∞–¥–∞—ë–º ID-–∫–æ–ª–æ–Ω–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å =====
    # HLA: sample_id
    if "sample_id" in hla_df.columns:
        hla_id_series = hla_df["sample_id"].astype("string").str.strip().replace({"": pd.NA})
    else:
        hla_id_series = coalesce_first_nonnull(hla_df, HLA_ID_COLS)
    # –í–∞–∫—Ü–∏–Ω—ã: ZLIMS ID
    if "ZLIMS ID" in vacc_df.columns:
        vacc_id_col = "ZLIMS ID"
    else:
        vacc_id_col = pick_first_or_none(vacc_df if "vacc_df" in locals() else df, VACC_ID_COLS)

    with st.expander("–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ ID-–∫–æ–ª–æ–Ω–∫–∏", expanded=False):
        st.write({
            "HLA_ID_candidates_present": [c for c in HLA_ID_COLS if c in hla_df.columns],
            "HLA_ID_used_nonnull": int(hla_id_series.notna().sum()) if hla_id_series is not None else 0,
            "VACC_ID_col_used": vacc_id_col,
        })
    if hla_id_series is None or hla_id_series.notna().sum() == 0 or not vacc_id_col:
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å ID –≤ –æ–¥–Ω–æ–º –∏–∑ —Ñ–∞–π–ª–æ–≤ (HLA –∏–ª–∏ –≤–∞–∫—Ü–∏–Ω—ã). –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫.")
        st.stop()

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω–∞–ª–∏–∑–∞
    c1, c2, c3 = st.columns(3)
    with c1:
        allele_level = st.selectbox("HLA: —É—Ä–æ–≤–µ–Ω—å –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –∞–ª–ª–µ–ª—è", [1, 2], index=0, help="1 ‚Üí A*01; 2 ‚Üí A*01:01")
    with c2:
        min_carriers = st.number_input("–ú–∏–Ω. —á–∏—Å–ª–æ –∫–æ–ø–∏–π –∞–ª–ª–µ–ª—è –¥–ª—è –ø–æ–∫–∞–∑–∞", min_value=1, value=5, step=1)
    with c3:
        genes_all = sorted({c.split("_")[0] for c in hla_df.columns if "_" in str(c)})
        genes_pick = st.multiselect("–ì–µ–Ω—ã HLA", genes_all, default=genes_all)

    # –í–∞–∫—Ü–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ + –≤–∞–ª–∏–¥–Ω—ã–π measles_result
    def _as_bool1(s):
        return s.astype(str).str.lower().isin(["1", "true", "yes", "–¥–∞", "y", "–∏—Å—Ç–∏–Ω–∞"])
    meas_res_col = "measles_result"
    meas_vacc_col = "measles_vaccine_info"
    if meas_res_col not in vacc_df.columns or meas_vacc_col not in vacc_df.columns:
        st.warning("–í —Ç–∞–±–ª–∏—Ü–µ –≤–∞–∫—Ü–∏–Ω–∞—Ü–∏–π –Ω–µ—Ç –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ measles_result / measles_vaccine_info.")
        st.stop()
    vacc_work = vacc_df.copy()
    # —Ç–æ–ª—å–∫–æ –≤–∞–∫—Ü–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ
    vacc_work = vacc_work[_as_bool1(vacc_work[meas_vacc_col])]
    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: —á–∏—Å–ª–æ–≤–æ–π, –∏—Å–∫–ª—é—á–∞–µ–º -1
    meas_res = pd.to_numeric(vacc_work[meas_res_col], errors="coerce")
    vacc_work = vacc_work.loc[meas_res.isin([0, 1])].copy()
    vacc_work[vacc_id_col] = vacc_work[vacc_id_col].astype(str)
    vacc_work["Group"] = meas_res.loc[vacc_work.index].astype(int)
    # –ì—Ä—É–ø–ø–∞ –ø–æ ID (–¥–ª—è merge)
    groups = vacc_work[[vacc_id_col, "Group"]].rename(columns={vacc_id_col: "ID"}).dropna()
    groups["ID"] = groups["ID"].astype(str)

    # –ü—Ä–∏–≤–æ–¥–∏–º HLA –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –≥–µ–Ω–∞–º
    if genes_pick:
        # –æ—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –≥–µ–Ω—ã + –≤—Å–µ id-–∫–∞–Ω–¥–∏–¥–∞—Ç—ã (–¥–ª—è –∫–æ–∞–ª–µ—Å—Ü–µ–Ω—Ü–∏–∏)
        id_cols_present = [c for c in HLA_ID_COLS if c in hla_df.columns]
        gene_cols = [c for c in hla_df.columns if "_" in str(c) and c.split("_")[0] in genes_pick]
        keep_cols = id_cols_present + gene_cols
        hla_sub = hla_df[keep_cols].copy()
    else:
        hla_sub = hla_df.copy()
    # —Ñ–æ—Ä–º–∏—Ä—É–µ–º –µ–¥–∏–Ω—É—é –∫–æ–ª–æ–Ω–∫—É ID –∏–∑ –∫–æ–∞–ª–µ—Å—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    hla_sub["ID"] = hla_id_series.astype("string").str.strip()
    hla_sub = hla_sub[hla_sub["ID"].notna() & (hla_sub["ID"] != "")]

    # Long-—Ñ–æ—Ä–º–∞ HLA
    try:
        hla_long = process_hla_long(hla_sub, allele_level)
        hla_long["ID"] = hla_long["ID"].astype(str)
    except Exception as e:
        st.error(f"HLA –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
        st.stop()

    # –ê–Ω–∞–ª–∏—Ç–∏–∫–∞
    res = counts_and_tests(hla_long, groups)
    if res.empty:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–æ–≤. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ ID –∏ —Ñ–∏–ª—å—Ç—Ä—ã.")
        st.stop()

    # –§–∏–ª—å—Ç—Ä –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–º—É —á–∏—Å–ª—É –∫–æ–ø–∏–π
    res = res[(res["count_res1"] + res["count_res0"]) >= int(min_carriers)]

    st.markdown("### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞—Å—Å–æ—Ü–∏–∞—Ü–∏–π (œá¬≤ / Fisher, FDR BH)")
    show_cols = ["Gene","Allele","count_res1","count_res0","n_res1","n_res0","freq_res1","freq_res0","delta_freq","test","p_value","p_fdr_bh","signif_fdr"]
    st.dataframe(res[show_cols], hide_index=True, use_container_width=True)

    # –¢–æ–ø-–∞–ª–ª–µ–ª–∏ –ø–æ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏
    st.markdown("### –¢–æ–ø-–∞–ª–ª–µ–ª–µ–π –ø–æ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ (‚â§ 20)")
    top = res.nsmallest(20, ["p_fdr_bh", "p_value"])
    if not top.empty:
        # –ø–æ—Å—Ç—Ä–æ–∏–º —á–∞—Å—Ç–æ—Ç—ã –¥–ª—è —Ç–æ–ø-–∞–ª–ª–µ–ª–µ–π (–ø–ª–æ—Å–∫–∞—è –º–µ—Ç–∫–∞ –≤–º–µ—Å—Ç–æ MultiIndex)
        freq_df = top[["Gene","Allele","freq_res0","freq_res1"]].copy()
        freq_df["label"] = (freq_df["Gene"].astype(str) + ":" +
                            freq_df["Allele"].astype(str))
        freq_df = freq_df.set_index("label")[["freq_res0","freq_res1"]]
        st_bar_chart_safe(freq_df)
    else:
        st.info("–ù–µ—Ç –∞–ª–ª–µ–ª–µ–π, —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—è—é—â–∏—Ö —Ñ–∏–ª—å—Ç—Ä–∞–º.")

    # –≠–∫—Å–ø–æ—Ä—Ç
    st.markdown("### –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    st.download_button(
        "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (CSV)",
        data=res.to_csv(index=False).encode("utf-8"),
        file_name="hla_measles_associations.csv",
        mime="text/csv",
    )

#############################
# Tab4: HLA √ó measles_ME_ml
#############################
with st.expander("üß¨‚áÑüíâ HLA √ó Measles (–∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç–∏—Ç—Ä)", expanded=False):
    st.subheader("–ê—Å—Å–æ—Ü–∏–∞—Ü–∏–∏ HLA ‚Üî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–Ω—Ç–∏—Ç–µ–ª (measles_ME_ml)")

    # –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–æ–Ω–∫–∏ —Å –∞–Ω—Ç–∏—Ç–µ–ª–∞–º–∏
    meas_q_col = "measles_ME_ml"
    if meas_q_col not in vacc_df.columns or meas_vacc_col not in vacc_df.columns:
        st.warning("–í —Ç–∞–±–ª–∏—Ü–µ –≤–∞–∫—Ü–∏–Ω–∞—Ü–∏–π –Ω–µ—Ç measles_ME_ml / measles_vaccine_info.")
        st.stop()

    # —Ç–æ–ª—å–∫–æ –≤–∞–∫—Ü–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å –≤–∞–ª–∏–¥–Ω—ã–º —á–∏—Å–ª–æ–º –∞–Ω—Ç–∏—Ç–µ–ª
    vacc_q = vacc_df[_as_bool1(vacc_df[meas_vacc_col])].copy()
    vacc_q[meas_q_col] = pd.to_numeric(vacc_q[meas_q_col], errors="coerce")
    vacc_q = vacc_q.dropna(subset=[meas_q_col])

    groups_q = vacc_q[[vacc_id_col, meas_q_col]].rename(
        columns={vacc_id_col: "ID", meas_q_col: "Antibody"}
    )
    groups_q["ID"] = groups_q["ID"].astype(str)

    # long HLA –¥–ª—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ + —Å—Ç—Ä–æ–∫–æ–≤—ã–µ ID
    hla_sub_q = hla_sub.copy()
    hla_long_q = process_hla_long(hla_sub_q, allele_level)
    hla_long_q["ID"] = hla_long_q["ID"].astype(str)
    # –ø—Ä–∏–≤–æ–¥–∏–º ID –≤ —Ç–∞–±–ª–∏—Ü–µ –≤–∞–∫—Ü–∏–Ω–∞—Ü–∏–π –∫ —Å—Ç—Ä–æ–∫–µ –ø–µ—Ä–µ–¥ merge
    vacc_df[vacc_id_col] = vacc_df[vacc_id_col].astype(str)
    merged_q = pd.merge(
        hla_long_q,
        vacc_df[[vacc_id_col, "measles_ME_ml", "cohort_region"]].rename(columns={vacc_id_col: "ID"}),
        on="ID",
        how="inner"
    )
    st.write("–°–æ–≤–º–µ—â–µ–Ω–æ —Å—Ç—Ä–æ–∫ (–∞–ª–ª–µ–ª—å–Ω—ã–µ –∑–∞–ø–∏—Å–∏):", merged_q.shape)

    if merged_q.empty:
        st.warning("–ù–µ—Ç –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π ID –º–µ–∂–¥—É HLA –∏ –≤–∞–∫—Ü–∏–Ω–∞—Ü–∏–µ–π.")
    else:
        # –ª–æ–≥-—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è —Ç–∏—Ç—Ä–æ–≤
        merged_q["measles_ME_log10"] = np.log10(1 + merged_q["measles_ME_ml"].clip(lower=0))
        merged_q["measles_ME_int"] = merged_q["measles_ME_ml"].fillna(0).astype(int)

        st.write("–ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:", merged_q.head())

        import statsmodels.formula.api as smf

        results_by_region = {}
        for region, df_region in merged_q.groupby("cohort_region"):
            if df_region["measles_ME_log10"].nunique() < 2:
                continue
            try:
                # –ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è log10 —Ç–∏—Ç—Ä–∞ ~ –Ω–∞–ª–∏—á–∏–µ –∞–ª–ª–µ–ª—è (–ø—Ä–∏–º–µ—Ä: A*01:01)
                # –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è: –ø—Ä–æ–≤–µ—Ä–∏–º –∫–∞–∂–¥—ã–π –∞–ª–ª–µ–ª—å –æ—Ç–¥–µ–ª—å–Ω–æ
                region_results = []
                # –ø–æ–¥–≥–æ—Ç–æ–≤–∏–º titer per ID
                titers = (df_region.groupby("ID")["measles_ME_log10"]
                                   .first()
                                   .to_frame("measles_ME_log10"))
                for allele in sorted(df_region["Allele"].dropna().unique()):
                    pres = (df_region.assign(allele_present=df_region["Allele"].eq(allele).astype(int))
                                     .groupby("ID")["allele_present"].max()
                                     .to_frame("allele_present"))
                    df_tmp = titers.join(pres, how="left").fillna({"allele_present":0})
                    if df_tmp["allele_present"].nunique() < 2:
                        continue
                    model = smf.ols("measles_ME_log10 ~ allele_present", data=df_tmp).fit()
                    region_results.append({
                        "region": region,
                        "allele": allele,
                        "coef": model.params.get("allele_present", np.nan),
                        "pval": model.pvalues.get("allele_present", np.nan),
                        "n": int(df_tmp.shape[0]),
                    })
                results_by_region[region] = pd.DataFrame(region_results)
            except Exception as e:
                st.write(f"–û—à–∏–±–∫–∞ –≤ —Ä–µ–≥–∏–æ–Ω–µ {region}: {e}")
        if results_by_region:
            for region, df_r in results_by_region.items():
                st.subheader(f"–†–µ–≥–∏–æ–Ω: {region}")
                st.dataframe(df_r.sort_values("pval").head(20))
        else:
            st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º.")

    merged_q = hla_long_q.merge(groups_q, on="ID", how="inner")
    res_q = []
    for g in sorted(merged_q["Gene"].unique()):
        sub = merged_q[merged_q["Gene"] == g]
        for allele in sub["Allele"].unique():
            # –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º –¥–æ —É—Ä–æ–≤–Ω—è –ø–∞—Ü–∏–µ–Ω—Ç–∞ (—á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–±–ª—é–¥–µ–Ω–∏—è)
            pres = (sub.assign(is_a=sub["Allele"].eq(allele).astype(int))
                      .groupby("ID")["is_a"].max())
            ant = sub.groupby("ID")["Antibody"].first()
            df_a = pd.concat([pres, ant], axis=1).dropna()
            vals_yes = df_a.loc[df_a["is_a"]==1, "Antibody"]
            vals_no  = df_a.loc[df_a["is_a"]==0, "Antibody"]
            if len(vals_yes) < 3 or len(vals_no) < 3:
                continue
            try:
                stat, p = mannwhitneyu(vals_yes, vals_no, alternative="two-sided")
                res_q.append({
                    "Gene": g,
                    "Allele": allele,
                    "n_carriers": int(len(vals_yes)),
                    "n_noncarriers": int(len(vals_no)),
                    "mean_carriers": vals_yes.mean(),
                    "mean_noncarriers": vals_no.mean(),
                    "delta_mean": vals_yes.mean() - vals_no.mean(),
                    "p_value": p
                })
            except Exception:
                continue
    res_q = pd.DataFrame(res_q)
    if res_q.empty:
        st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.")
        st.stop()

    # FDR –∫–æ—Ä—Ä–µ–∫—Ü–∏—è
    reject, pcor, _, _ = multipletests(res_q["p_value"], method="fdr_bh")
    res_q["p_fdr_bh"] = pcor
    res_q["signif_fdr"] = reject
    res_q = res_q.sort_values("p_fdr_bh")

    st.markdown("### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã U-—Ç–µ—Å—Ç–∞ (–ú–∞–Ω–Ω–∞‚Äì–£–∏—Ç–Ω–∏)")
    st.dataframe(res_q, hide_index=True, use_container_width=True)

    # –¢–æ–ø-–∞–ª–ª–µ–ª–∏
    st.markdown("### –ë–æ–∫—Å–ø–ª–æ—Ç—ã –¥–ª—è —Ç–æ–ø-–∞–ª–ª–µ–ª–µ–π")
    top_q = res_q.nsmallest(6, "p_fdr_bh")
    for _, row in top_q.iterrows():
        g, a = row["Gene"], row["Allele"]
        sub = merged_q.assign(
            Carrier=merged_q["Allele"].eq(a).map({True: f"{g}-{a}", False: "Other"})
        )
        fig, ax = plt.subplots(figsize=(5,4))
        sns.boxplot(data=sub, x="Carrier", y="Antibody", ax=ax)
        sns.stripplot(data=sub, x="Carrier", y="Antibody", color="black", size=3, alpha=0.6, ax=ax)
        ax.set_title(f"{g}-{a} (p={row['p_fdr_bh']:.3g})")
        st.pyplot(fig)
    # –≠–∫—Å–ø–æ—Ä—Ç
    st.download_button(
        "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (CSV)",
        data=res_q.to_csv(index=False).encode("utf-8"),
        file_name="hla_measles_antibody_levels.csv",
        mime="text/csv",
    )
